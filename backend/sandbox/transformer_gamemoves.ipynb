{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import IterableDataset, TensorDataset\n",
    "import torch_optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(106, 64), nn.ReLU(), nn.Linear(64, d_model))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_model, action_dim):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(d_model, 64), nn.ReLU(), nn.Linear(64, action_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, max_seq_length:int, feature_dim:int, action_dim:int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout=0)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, d_hid, dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Sequential(nn.Linear(feature_dim, d_model), nn.Sigmoid())\n",
    "        #self.encoder = Encoder(d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, action_dim)\n",
    "        #self.decoder = Decoder(d_model, action_dim)\n",
    "        self.src_mask = generate_square_subsequent_mask(self.max_seq_length)\n",
    "\n",
    "        #self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        self.src_mask = self.src_mask.to(device=src.device)\n",
    "        assert src.shape[1] == self.max_seq_length, f\"{src.shape[1]} != {self.max_seq_length}\"\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        #output = src\n",
    "\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "def generate_square_subsequent_mask(sz: int) -> torch.Tensor:\n",
    "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModule(pl.LightningModule):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.model = TransformerModel(max_seq_length=32, feature_dim=106, action_dim=50, d_model=128, nhead=2, d_hid=64, nlayers=3)\n",
    "    \n",
    "    def forward(self, batch, batch_idx):\n",
    "        features = batch[0]\n",
    "        outputs = batch[1].long()\n",
    "\n",
    "        batch_size = features.shape[0]\n",
    "\n",
    "        # training_step defines the train loop.\n",
    "\n",
    "        #z = self.encoder(features)\n",
    "        #x_hat = self.decoder(z, 50)\n",
    "\n",
    "\n",
    "        x_hat = self.model(features)\n",
    "\n",
    "        x_hat = x_hat.view(-1,50)\n",
    "        outputs = outputs.view(-1)\n",
    "\n",
    "        assert outputs.shape == (32*batch_size,), f\"{outputs.shape}\"\n",
    "        assert x_hat.shape == (32*batch_size,50)\n",
    "\n",
    "\n",
    "        #loss = F.mse_loss(x_hat, outputs)\n",
    "        #print(x_hat.view(-1,50).shape)\n",
    "        #print(outputs.view(-1).shape)\n",
    "        loss = nn.CrossEntropyLoss(ignore_index=-1)(x_hat, outputs)\n",
    "\n",
    "        assert not torch.any(torch.isnan(loss))\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return {\"loss\":self.forward(batch, batch_idx)}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # print(\"BATCH\")\n",
    "        # features = batch[0][0]\n",
    "        # outputs = batch[1][0].squeeze(dim=1).long()\n",
    "        # print(type(batch))\n",
    "        # print(features)\n",
    "        # print(outputs)\n",
    "        # print(features.shape)\n",
    "        # print(outputs.shape)\n",
    "        # assert False\n",
    "        loss = self.forward(batch, batch_idx)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        #optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        #optimizer = torch.optim.AdamW(self.parameters(), lr=5e-5)\n",
    "\n",
    "        #optimizer = torch.optim.SGD(self.parameters(), lr=0.001)\n",
    "\n",
    "        optimizer = torch_optimizer.Shampoo(self.parameters(), lr=1e-1)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "td =torch.load(\"../training_data.pt\")\n",
    "features = td[\"train_data\"]\n",
    "outputs = td[\"train_output\"]\n",
    "dataset = TensorDataset(features, outputs)\n",
    "train_loader = DataLoader(dataset, batch_size=16)\n",
    "\n",
    "#test_loader = DataLoader(dataset)\n",
    "\n",
    "td =torch.load(\"../validation_data.pt\")\n",
    "features = td[\"train_data\"]\n",
    "outputs = td[\"train_output\"]\n",
    "dataset = TensorDataset(features, outputs)\n",
    "val_loader = DataLoader(dataset, batch_size=128)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | encoder | Encoder          | 7.0 K \n",
      "1 | decoder | Decoder          | 3.5 K \n",
      "2 | model   | TransformerModel | 269 K \n",
      "---------------------------------------------\n",
      "280 K     Trainable params\n",
      "0         Non-trainable params\n",
      "280 K     Total params\n",
      "1.120     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90637a706dca4036882a948f1c82ddd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9edc549fa1e4afea7d50f25604b574e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7b6158ee634e44836c7fdcd49db84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a7dea38f4241b8844452862293d594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8be680cfbf401fa3dc83e8eaba3cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ed956703fc458bb1a9a162e9f21b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3cce1c1ac241a4a3af6b79d8b3b051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91f979108714107b062395dacea186a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320e7fb692184cd4b9ac304a33f8df75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70ec132e3324354b86d06e994c80028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dff103a2b854808aa4655cbfaa03be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/pawn/miniconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/pawn/miniconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/pawn/miniconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/pawn/miniconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 972, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/pawn/miniconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/pawn/miniconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/pawn/miniconda3/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/pawn/miniconda3/lib/python3.9/asyncio/base_events.py\", line 1854, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "  File \"/home/pawn/miniconda3/lib/python3.9/selectors.py\", line 469, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "  File \"/home/pawn/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 38681) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "autoencoder = LitModule(Encoder(3), Decoder(3, 50))\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# train model\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=1, callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\")])\n",
    "trainer.fit(model=autoencoder, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8133a274dd2e39d1a7758d93ca9e633cfd2e155f9714bb4b806ffa082ebb41a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
